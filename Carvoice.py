{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "语音识别&神经网络代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc,delta\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import sample\n",
    "import numpy as np\n",
    "path_film = os.path.abspath('.')\n",
    "path = path_film + \"./newvoice/\"#这里是自己的数据集所在文件夹，尽量不要出现中文\n",
    "#使用one-hot编码，将离散特征的取值扩展到了欧式空间\n",
    "#全局one-hot编码空间\n",
    "label_binarizer = \"\"\n",
    "from pyaudio import PyAudio, paInt16 \n",
    "import numpy as np \n",
    "from datetime import datetime \n",
    "import wave\n",
    "class recoder:\n",
    "    NUM_SAMPLES = 2000      #pyaudio内置缓冲大小\n",
    "    SAMPLING_RATE = 8000    #取样频率\n",
    "    LEVEL = 500         #声音保存的阈值\n",
    "    COUNT_NUM = 20      #NUM_SAMPLES个取样之内出现COUNT_NUM个大于LEVEL的取样则记录声音\n",
    "    SAVE_LENGTH = 8         #声音记录的最小长度：SAVE_LENGTH * NUM_SAMPLES 个取样\n",
    "    TIME_COUNT = 60     #录音时间，单位s\n",
    "\n",
    "    Voice_String = []\n",
    "\n",
    "    def savewav(self,filename):\n",
    "        wf = wave.open(filename, 'wb') \n",
    "        wf.setnchannels(1) \n",
    "        wf.setsampwidth(2) \n",
    "        wf.setframerate(self.SAMPLING_RATE) \n",
    "        wf.writeframes(np.array(self.Voice_String).tostring()) \n",
    "        # wf.writeframes(self.Voice_String.decode())\n",
    "        wf.close() \n",
    "\n",
    "    def recoder(self):\n",
    "        pa = PyAudio() \n",
    "        stream = pa.open(format=paInt16, channels=1, rate=self.SAMPLING_RATE, input=True, \n",
    "            frames_per_buffer=self.NUM_SAMPLES) \n",
    "        save_count = 0 \n",
    "        save_buffer = [] \n",
    "        time_count = self.TIME_COUNT\n",
    "        print('running!')\n",
    "        while True:\n",
    "            time_count -= 1\n",
    "            \n",
    "            # print time_count\n",
    "            # 读入NUM_SAMPLES个取样\n",
    "            string_audio_data = stream.read(self.NUM_SAMPLES) \n",
    "            # 将读入的数据转换为数组\n",
    "            audio_data = np.fromstring(string_audio_data, dtype=np.short)\n",
    "            # 计算大于LEVEL的取样的个数\n",
    "            large_sample_count = np.sum( audio_data > self.LEVEL )\n",
    "            #print(np.max(audio_data))\n",
    "            # 如果个数大于COUNT_NUM，则至少保存SAVE_LENGTH个块\n",
    "            if large_sample_count > self.COUNT_NUM:\n",
    "                save_count = self.SAVE_LENGTH \n",
    "            else: \n",
    "                save_count -= 1\n",
    "\n",
    "            if save_count < 0:\n",
    "                save_count = 0 \n",
    "\n",
    "            if save_count > 0 : \n",
    "            # 将要保存的数据存放到save_buffer中\n",
    "                #print  save_count > 0 and time_count >0\n",
    "                save_buffer.append( string_audio_data ) \n",
    "            else: \n",
    "            #print save_buffer\n",
    "            # 将save_buffer中的数据写入WAV文件，WAV文件的文件名是保存的时刻\n",
    "                #print \"debug\"\n",
    "                if len(save_buffer) > 0 : \n",
    "                    self.Voice_String = save_buffer\n",
    "                    save_buffer = [] \n",
    "                    print(\"Recode a piece of  voice successfully!\")\n",
    "                    return True\n",
    "            if time_count==0: \n",
    "                if len(save_buffer)>0:\n",
    "                    self.Voice_String = save_buffer\n",
    "                    save_buffer = [] \n",
    "                    print(\"Recode a piece of  voice successfully!\")\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "\n",
    "                \n",
    "def def_one_hot(x):\n",
    "    if label_binarizer == \"\":\n",
    "        binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "    else:\n",
    "        binarizer = label_binarizer\n",
    "    ##这里有问题\n",
    "    y = binarizer.fit_transform(x)\n",
    "    return y\n",
    " \n",
    "def read_wav_path(path):\n",
    "    map_path = []\n",
    "    labels = []\n",
    "    for x in os.listdir(path):\n",
    "        [map_path, labels] = circle(path, x, map_path, labels)\n",
    "    return map_path, labels\n",
    " \n",
    "##循环遍历\n",
    "def circle(path,x,map_path,labels):\n",
    "    if os.path.isfile(str(path) + str(x)):\n",
    "        map_path.append(str(path) + str(x))\n",
    "    else:\n",
    "        for y in os.listdir(str(path) + str(x)+\"/\"):\n",
    "            labels.append(x)\n",
    "            circle(str(path) + str(x)+\"/\",y,map_path,labels)\n",
    "    return map_path,labels\n",
    "#map_path, labels = read_wav_path(path)\n",
    "def def_wav_read_mfcc(file_name):\n",
    "    fs, audio = wav.read(file_name)\n",
    "    processed_audio = mfcc(audio, samplerate=fs)\n",
    "    return processed_audio\n",
    " \n",
    "def find_matrix_max_shape(audio):\n",
    "    ##这个里面的wav文件的长度不一，现在选出其中最大行列的h(高度),l(长度)\n",
    "    h, l = 0, 0\n",
    "    for a in audio:\n",
    "        a, b = np.array(a).shape\n",
    "        if a > h:\n",
    "            h=a\n",
    "        if b > l:\n",
    "            l=b\n",
    "    return h, l\n",
    " \n",
    "def matrix_make_up(audio):\n",
    "    ##找出wav文件中宽高最大的参数h,l\n",
    "    h, l = find_matrix_max_shape(audio)\n",
    "    ##对于长度不够的，会填充0\n",
    "    new_audio = []\n",
    "    for aa in audio:\n",
    "        a, b = np.array(aa).shape\n",
    "        zeros_matrix = np.zeros([h, l],np.int8)\n",
    "        for i in range(a):\n",
    "            for j in range(b):\n",
    "                zeros_matrix[i, j]=zeros_matrix[i,j]+aa[i,j]\n",
    "        new_audio.append(zeros_matrix)\n",
    "    return new_audio,h,l\n",
    " \n",
    "def read_wav_matrix(path):\n",
    "    ##获取该路径下面的文件以及标签\n",
    "    map_path, labels = read_wav_path(path)\n",
    "    ##添加文件夹的名称在里面\n",
    " \n",
    "    ##提取mfcc的特征\n",
    "    audio = []\n",
    "    for idx, folder in enumerate(map_path):\n",
    "        processed_audio_delta = def_wav_read_mfcc(folder)\n",
    "        audio.append(processed_audio_delta)\n",
    "    ##提取mfcc的特征\n",
    "    ##统一长度的wav文件\n",
    "    x_data,h,l = matrix_make_up(audio)\n",
    "    ##统一长度的wav文件\n",
    "    ##音频文件数字化\n",
    "    x_data = np.array(x_data)\n",
    "    ##标签变成热码\n",
    "    x_label = np.array(def_one_hot(labels))\n",
    "    return x_data, x_label, h, l\n",
    "  \n",
    "#初始化权值\n",
    "def weight_variable(shape,name):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.01)#生成一个截断的正态分布\n",
    "    return tf.Variable(initial,name=name)\n",
    " \n",
    "#初始化偏置\n",
    "def bias_variable(shape,name):\n",
    "    initial = tf.constant(0.01,shape=shape)\n",
    "    return tf.Variable(initial,name=name)\n",
    " \n",
    "#卷积层\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    " \n",
    "#池化层\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    " \n",
    "def xunlianlo(path):\n",
    "    tf.reset_default_graph()  \n",
    "    x_train, y_train, h, l = read_wav_matrix(path)\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(x_train, y_train, test_size=0.2)\n",
    "    m,n = y_tr.shape\n",
    "    # 定义两个placeholder\n",
    "    x = tf.placeholder(tf.float32, [None, h, l], name='x-input')\n",
    "    y = tf.placeholder(tf.float32, [None, n], name='y-input')\n",
    "    # 改变x的格式转为4D的向量[batch, in_height, in_width, in_channels]`\n",
    "    x_image = tf.reshape(x, [-1, h, l, 1], name='x_image')\n",
    " \n",
    "    # 初始化第一个卷积层的权值和偏置\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32], name='W_conv1')  # 5*5的采样窗口，32个卷积核从3个平面抽取特征\n",
    "    b_conv1 = bias_variable([32], name='b_conv1')  # 每一个卷积核一个偏置值\n",
    "    # 把x_image和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数\n",
    "    conv2d_1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "    h_conv1 = tf.nn.leaky_relu(conv2d_1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)  # 进行max-pooling\n",
    " \n",
    "    # 初始化第二个卷积层的权值和偏置\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64], name='W_conv2')  # 5*5的采样窗口，64个卷积核从32个平面抽取特征\n",
    "    b_conv2 = bias_variable([64], name='b_conv2')  # 每一个卷积核一个偏置值\n",
    "    # 把h_pool1和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数\n",
    "    conv2d_2 = conv2d(h_pool1, W_conv2) + b_conv2\n",
    "    h_conv2 = tf.nn.leaky_relu(conv2d_2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)  # 进行max-pooling\n",
    " \n",
    " \n",
    "    # 初始化第一个全连接层的权值////////这里需要修改两个参数\n",
    "    W_fc1 = weight_variable([106 * 4 * 64, 10], name='W_fc1')  # 上一场有75*75*64个神经元，全连接层有1024个神经元\n",
    "    b_fc1 = bias_variable([10], name='b_fc1')  # 1024个节点\n",
    "    # 把池化层2的输出扁平化为1维\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 106 * 4 * 64], name='h_pool2_flat')\n",
    " \n",
    "    # 求第一个全连接层的输出\n",
    "    wx_plus_b1 = tf.matmul(h_pool2_flat, W_fc1) + b_fc1\n",
    "    h_fc1 = tf.nn.leaky_relu(wx_plus_b1)\n",
    " \n",
    "    # keep_prob用来表示神经元的输出概率\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name='h_fc1_drop')\n",
    "    print(\"..................................................\")\n",
    "    # 初始化第二个全连接层\n",
    "    W_fc2 = weight_variable([10, n], name='W_fc2')\n",
    "    b_fc2 = bias_variable([n], name='b_fc2')\n",
    "    wx_plus_b2 = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    " \n",
    "    # 计算输出\n",
    "    prediction = tf.nn.leaky_relu(wx_plus_b2)\n",
    "    tf.add_to_collection('predictions', prediction)\n",
    "    p = tf.nn.softmax(wx_plus_b2)\n",
    "    tf.add_to_collection('p', p)\n",
    "    # 交叉熵代价函数\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction),\n",
    "                                   name='cross_entropy')\n",
    " \n",
    "    # 使用AdamOptimizer进行优化\n",
    "    train_step = tf.train.AdamOptimizer(1e-5).minimize(cross_entropy)\n",
    "    # 求准确率\n",
    "    # 结果存放在一个布尔列表中\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))  # argmax返回一维张量中最大的值所在的位置\n",
    "    # 求准确率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    #保存模型使用环境\n",
    "    saver = tf.train.Saver()\n",
    " \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    " \n",
    "        # 创建一个协调器，管理线程\n",
    "        #coord = tf.train.Coordinator()\n",
    "        # 启动QueueRunner, 此时文件名队列已经进队\n",
    "        #threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    " \n",
    "        for i in range(50000):\n",
    "            # 训练模型\n",
    "            ind = sample(range(len(X_tr)), 20)\n",
    "            batch_x = X_tr[ind]\n",
    "            batch_y = y_tr[ind]\n",
    "            sess.run(train_step, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0})\n",
    "            if i%100==0:\n",
    "                train_acc = sess.run(accuracy, feed_dict={x: x_train, y: y_train, keep_prob: 1.0})\n",
    "                print(\"训练第 \" + str(i) + \" 次, 训练集准确率= \" + str(train_acc))\n",
    "                if train_acc>=0.98:\n",
    "                    print(\"模型训练成功了\")\n",
    "                    saver.save(sess, 'nn1/my_net.ckpt')\n",
    "                    break\n",
    "def test_main(X_te,y_te):\n",
    "    # 本地情况下生成数据\n",
    "    #X_te,y_te\n",
    "    m,n = y_te.shape\n",
    " \n",
    "    # 迭代网络\n",
    "    with tf.Session() as sess:\n",
    "        # 保存模型使用环境\n",
    "        saver = tf.train.import_meta_graph(\"nn1/my_net.ckpt.meta\")\n",
    "        saver.restore(sess, 'nn1/my_net.ckpt')\n",
    "        predictions = tf.get_collection('predictions')[0]\n",
    "        p = tf.get_collection('p')[0]\n",
    "        graph = tf.get_default_graph()\n",
    "        input_x = graph.get_operation_by_name('x-input').outputs[0]\n",
    "        keep_prob = graph.get_operation_by_name('keep_prob').outputs[0]\n",
    "        count=0\n",
    "        for i in range(m):\n",
    "            result = sess.run(predictions, feed_dict={input_x: np.array([X_te[i]]),keep_prob:1.0})\n",
    "            haha = sess.run(p, feed_dict={input_x: np.array([X_te[i]]), keep_prob: 1.0})\n",
    "            print(\"实际 :\"+str(np.argmax(y_te[i]))+\" ,预测: \"+str(np.argmax(result))+\" ,预测可靠度: \"+str(np.max(haha)))\n",
    "            if str(np.argmax(y_te[i]))==str(np.argmax(result)):\n",
    "                count=count+1\n",
    "        print(\"准确率:\"+str(count/m))    \n",
    "                    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\n",
      "训练第 0 次, 训练集准确率= 0.17142858\n",
      "训练第 100 次, 训练集准确率= 0.2761905\n",
      "训练第 200 次, 训练集准确率= 0.36095238\n",
      "训练第 300 次, 训练集准确率= 0.41904762\n",
      "训练第 400 次, 训练集准确率= 0.39238095\n",
      "训练第 500 次, 训练集准确率= 0.3495238\n",
      "训练第 600 次, 训练集准确率= 0.36666667\n",
      "训练第 700 次, 训练集准确率= 0.4304762\n",
      "训练第 800 次, 训练集准确率= 0.6390476\n",
      "训练第 900 次, 训练集准确率= 0.7076191\n",
      "训练第 1000 次, 训练集准确率= 0.7542857\n",
      "训练第 1100 次, 训练集准确率= 0.8057143\n",
      "训练第 1200 次, 训练集准确率= 0.83619046\n",
      "训练第 1300 次, 训练集准确率= 0.8695238\n",
      "训练第 1400 次, 训练集准确率= 0.8752381\n",
      "训练第 1500 次, 训练集准确率= 0.9\n",
      "训练第 1600 次, 训练集准确率= 0.90380955\n",
      "训练第 1700 次, 训练集准确率= 0.9085714\n",
      "训练第 1800 次, 训练集准确率= 0.9190476\n",
      "训练第 1900 次, 训练集准确率= 0.9352381\n",
      "训练第 2000 次, 训练集准确率= 0.9438095\n",
      "训练第 2100 次, 训练集准确率= 0.93904763\n",
      "训练第 2200 次, 训练集准确率= 0.94666666\n",
      "训练第 2300 次, 训练集准确率= 0.94857144\n",
      "训练第 2400 次, 训练集准确率= 0.9590476\n",
      "训练第 2500 次, 训练集准确率= 0.9590476\n",
      "训练第 2600 次, 训练集准确率= 0.9628571\n",
      "训练第 2700 次, 训练集准确率= 0.9647619\n",
      "训练第 2800 次, 训练集准确率= 0.96666664\n",
      "训练第 2900 次, 训练集准确率= 0.96666664\n",
      "训练第 3000 次, 训练集准确率= 0.97238094\n",
      "训练第 3100 次, 训练集准确率= 0.97238094\n",
      "训练第 3200 次, 训练集准确率= 0.9752381\n",
      "训练第 3300 次, 训练集准确率= 0.9790476\n",
      "训练第 3400 次, 训练集准确率= 0.9809524\n",
      "模型训练成功了\n"
     ]
    }
   ],
   "source": [
    "#模型训练函数\n",
    "xunlianlo(path)#自己的数据集，有些参数需要修改，记得问我"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h#测试成功后可以跑以下这一行，这个h参数为你的数据集最长mfcc特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'x-input_1' with dtype float and shape [?,424,13]\n\t [[node x-input_1 (defined at <ipython-input-15-3c223f725326>:21) ]]\n\nOriginal stack trace for 'x-input_1':\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 153, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-3c223f725326>\", line 21, in <module>\n    saver = tf.train.import_meta_graph(\"nn1/my_net.ckpt.meta\")\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1449, in import_meta_graph\n    **kwargs)[0]\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1473, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 857, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 443, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 236, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3751, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3751, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3641, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'x-input_1' with dtype float and shape [?,424,13]\n\t [[{{node x-input_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-52f9a3b2a8d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#m,n = y_train.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#X_tr, X_te, y_tr, y_te = train_test_split(x_train, y_train, test_size=0.2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtest_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_te\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-f9c511f8ba63>\u001b[0m in \u001b[0;36mtest_main\u001b[1;34m(X_te, y_te)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0minput_x\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_te\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m             \u001b[0mhaha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0minput_x\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_te\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"实际 :\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" ,预测: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" ,预测可靠度: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhaha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'x-input_1' with dtype float and shape [?,424,13]\n\t [[node x-input_1 (defined at <ipython-input-15-3c223f725326>:21) ]]\n\nOriginal stack trace for 'x-input_1':\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 153, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-3c223f725326>\", line 21, in <module>\n    saver = tf.train.import_meta_graph(\"nn1/my_net.ckpt.meta\")\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1449, in import_meta_graph\n    **kwargs)[0]\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1473, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 857, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 443, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 236, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3751, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3751, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3641, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "#分割测试集训练集                      #如果是使用已经训练好的参数，而本次打开没有训练过，可以用下面的代码分割一下训练集和测试集\n",
    "#x_train, y_train, h, l = read_wav_matrix(path)\n",
    "#m,n = y_train.shape\n",
    "#X_tr, X_te, y_tr, y_te = train_test_split(x_train, y_train, test_size=0.2)\n",
    "test_main(X_te,y_te)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全自动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recode a piece of  voice successfully!\n",
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n",
      "预测: 2预测可靠度:0.8025733\n",
      "左转\n",
      "running!\n",
      "Recode a piece of  voice successfully!\n",
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n",
      "预测: 3预测可靠度:0.46260172\n",
      "右转\n",
      "running!\n",
      "Recode a piece of  voice successfully!\n",
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n",
      "预测: 4预测可靠度:0.8303323\n",
      "慢速\n",
      "running!\n",
      "Recode a piece of  voice successfully!\n",
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n",
      "预测: 4预测可靠度:0.918018\n",
      "慢速\n",
      "running!\n",
      "Recode a piece of  voice successfully!\n",
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n",
      "预测: 1预测可靠度:0.99912125\n",
      "前进\n",
      "running!\n",
      "Recode a piece of  voice successfully!\n",
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n",
      "预测: 2预测可靠度:0.718632\n",
      "左转\n",
      "running!\n",
      "Recode a piece of  voice successfully!\n",
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n",
      "预测: 2预测可靠度:0.7493172\n",
      "左转\n",
      "running!\n",
      "Recode a piece of  voice successfully!\n",
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n",
      "预测: 2预测可靠度:0.9827512\n",
      "左转\n",
      "running!\n",
      "Recode a piece of  voice successfully!\n",
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n",
      "预测: 1预测可靠度:0.9176619\n",
      "前进\n",
      "running!\n",
      "Recode a piece of  voice successfully!\n",
      "INFO:tensorflow:Restoring parameters from nn1/my_net.ckpt\n",
      "预测: 5预测可靠度:0.7942768\n",
      "停止\n",
      "running!\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3c223f725326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavewav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tingzhi.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tingzhi.wav'\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#提取录音文件并做预处理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mprocessed_audio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mxx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprocessed_audio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mzeros_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\python_speech_features\\base.py\u001b[0m in \u001b[0;36mmfcc\u001b[1;34m(signal, samplerate, winlen, winstep, numcep, nfilt, nfft, lowfreq, highfreq, preemph, ceplifter, appendEnergy, winfunc)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNUMFRAMES\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnumcep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mEach\u001b[0m \u001b[0mrow\u001b[0m \u001b[0mholds\u001b[0m \u001b[1;36m1\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \"\"\"\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menergy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfbank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwinlen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwinstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnfilt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnfft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlowfreq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhighfreq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreemph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwinfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mfeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mfeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ortho'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnumcep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\python_speech_features\\base.py\u001b[0m in \u001b[0;36mfbank\u001b[1;34m(signal, samplerate, winlen, winstep, nfilt, nfft, lowfreq, highfreq, preemph, winfunc)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \"\"\"\n\u001b[0;32m     53\u001b[0m     \u001b[0mhighfreq\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mhighfreq\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0msignal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreemphasis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreemph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframesig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwinlen\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwinstep\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwinfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mpspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpowspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnfft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\python_speech_features\\sigproc.py\u001b[0m in \u001b[0;36mpreemphasis\u001b[1;34m(signal, coeff)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfiltered\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcoeff\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "h=424                #h参数为当前数据集的最长mfcc特征，短于此特征的mfcc特征矩阵会补零，如果直接跑这段代码，需要给h的值，如果前面刚训练过就不用\n",
    "l=13                 \n",
    "while(True):\n",
    "    r=recoder()                         #录音\n",
    "    r.recoder()\n",
    "    r.savewav('tingzhi.wav')              \n",
    "    fs, audio = wav.read('tingzhi.wav')   #提取录音文件并做预处理\n",
    "    processed_audio = mfcc(audio, samplerate=fs)\n",
    "    xx=processed_audio.astype(np.int8)\n",
    "    zeros_matrix = np.zeros([h, 13],np.int8)\n",
    "    a,b=processed_audio.shape\n",
    "    if a>h:\n",
    "        print('长度不符，重来！')\n",
    "        continue\n",
    "    for i in range(a):\n",
    "        for j in range(b):\n",
    "            zeros_matrix[i, j]=zeros_matrix[i,j]+processed_audio[i,j]\n",
    "    xx_data=zeros_matrix\n",
    "    with tf.Session() as sess:                                 #打开神经网络并做预测\n",
    "                # 保存模型使用环境\n",
    "                saver = tf.train.import_meta_graph(\"nn1/my_net.ckpt.meta\")\n",
    "                saver.restore(sess, 'nn1/my_net.ckpt')\n",
    "                predictions = tf.get_collection('predictions')[0]\n",
    "                p = tf.get_collection('p')[0]\n",
    "                graph = tf.get_default_graph()\n",
    "                input_x = graph.get_operation_by_name('x-input').outputs[0]\n",
    "                keep_prob = graph.get_operation_by_name('keep_prob').outputs[0] \n",
    "                result = sess.run(predictions, feed_dict={input_x: np.array([xx_data]),keep_prob:1.0})\n",
    "                haha = sess.run(p, feed_dict={input_x: np.array([xx_data]), keep_prob: 1.0})\n",
    "                print('预测: '+str(np.argmax(result))+'预测可靠度:' +str(np.max(haha)))\n",
    "    if str(np.argmax(result))=='0':                           #后期想拓展功能，训练好模型后在这里改就行，只要把print改成自己的代码就可以\n",
    "        print('快速')\n",
    "    if str(np.argmax(result))=='1':\n",
    "        print('前进') \n",
    "    if str(np.argmax(result))=='2':\n",
    "        print('左转')\n",
    "    if str(np.argmax(result))=='3':\n",
    "        print('右转')\n",
    "    if str(np.argmax(result))=='4':\n",
    "        print('慢速')\n",
    "    if str(np.argmax(result))=='5':\n",
    "        print('停止')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用来新建数据集用，可以字段定义词条\n",
    "记得先创建文件夹后录音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hazel\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recode a piece of  voice successfully!\n",
      "60\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "r=recoder()\n",
    "path_c= './newvoice/stop/'\n",
    "for i in range(60,61): #如果不是一次性录完，可以直接修改range的值，来接之前录过的文件名  注意！，如果文件名重名，原有文件会被覆盖\n",
    "    r.recoder()\n",
    "    r.savewav(path_c+'stop_me_'+str(i)+'.wav')\n",
    "    print(i)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()                 #这里的代码是用新的数据集时候需要用到的，跑这段代码后，查看h_pool2的结构\n",
    "x_train, y_train, h, l = read_wav_matrix(path)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(x_train, y_train, test_size=0.2)\n",
    "m,n = y_tr.shape\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, h, l], name='x-input')\n",
    "y = tf.placeholder(tf.float32, [None, n], name='y-input')\n",
    "# 改变x的格式转为4D的向量[batch, in_height, in_width, in_channels]`\n",
    "x_image = tf.reshape(x, [-1, h, l, 1], name='x_image')\n",
    "\n",
    "# 初始化第一个卷积层的权值和偏置\n",
    "W_conv1 = weight_variable([5, 5, 1, 32], name='W_conv1')  # 5*5的采样窗口，32个卷积核从3个平面抽取特征\n",
    "b_conv1 = bias_variable([32], name='b_conv1')  # 每一个卷积核一个偏置值\n",
    "# 把x_image和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数\n",
    "conv2d_1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "h_conv1 = tf.nn.leaky_relu(conv2d_1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)  # 进行max-pooling\n",
    "\n",
    "# 初始化第二个卷积层的权值和偏置\n",
    "W_conv2 = weight_variable([5, 5, 32, 64], name='W_conv2')  # 5*5的采样窗口，64个卷积核从32个平面抽取特征\n",
    "b_conv2 = bias_variable([64], name='b_conv2')  # 每一个卷积核一个偏置值\n",
    "# 把h_pool1和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数\n",
    "conv2d_2 = conv2d(h_pool1, W_conv2) + b_conv2\n",
    "h_conv2 = tf.nn.leaky_relu(conv2d_2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)  # 进行max-pooling\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_1:0' shape=(?, 106, 4, 64) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool2                   #这里的shape参数，200 4 64相乘，就要在前面做相应的修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
